{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KClxa9fdWWk8"
   },
   "source": [
    "### Brain Tumor classification using Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oq5gpZIeMtza"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9136\\3499704832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, save_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization,Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation,GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import imutils\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YaA5k6FM26u",
    "outputId": "d7d1e956-52b5-4c71-82fb-37417788c06a"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaIYpht1M73v",
    "outputId": "cf8bfd42-29d9-498d-ef88-5a633b4763e6"
   },
   "outputs": [],
   "source": [
    "!ls drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqhueziRWmdf"
   },
   "source": [
    "## Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 934
    },
    "id": "bF3qyzFKNK1v",
    "outputId": "0ca9ef7f-1f11-4018-b7af-eecaf40a314b"
   },
   "outputs": [],
   "source": [
    "data_dir = ('/content/drive/MyDrive/brain_tumour/Training')\n",
    "categories = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "images_path = ['/glioma/Tr-gl_0010.jpg', '/meningioma/Tr-meTr_0000.jpg', '/notumor/Tr-noTr_0000.jpg', '/pituitary/Tr-piTr_0000.jpg']\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    img = cv2.imread(data_dir + images_path[i])\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    plt.imshow(img)\n",
    "    plt.title(categories[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0HX4rDBWt4h"
   },
   "source": [
    "## Crpping Images Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AveB7JONMwF"
   },
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "\t\"\"\"\n",
    "\tFinds the extreme points on the image and crops the rectangular out of them\n",
    "\t\"\"\"\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "\t# threshold the image, then perform a series of erosions +\n",
    "\t# dilations to remove any small regions of noise\n",
    "\tthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "\tthresh = cv2.erode(thresh, None, iterations=2)\n",
    "\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "\t# find contours in thresholded image, then grab the largest one\n",
    "\tcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tc = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "\t# find the extreme points\n",
    "\textLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "\textRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "\textTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "\textBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\tADD_PIXELS = 0\n",
    "\tnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
    "\t\n",
    "\treturn new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76JGHUvIN0Lm"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('/content/drive/My Drive/brain_tumour/Training/meningioma/Tr-meTr_0000.jpg')\n",
    "img = cv2.resize(\n",
    "            img,\n",
    "            dsize=(224,224),\n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# threshold the image, then perform a series of erosions +\n",
    "# dilations to remove any small regions of noise\n",
    "thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "thresh = cv2.erode(thresh, None, iterations=2)\n",
    "thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "# find contours in thresholded image, then grab the largest one\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# find the extreme points\n",
    "extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "# add contour on the image\n",
    "img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n",
    "\n",
    "# add extreme points\n",
    "img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n",
    "\n",
    "# crop\n",
    "ADD_PIXELS = 0\n",
    "new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "aKX3q538N1Ke",
    "outputId": "8b23e1bf-e22a-46d0-f9ae-f7e9f04d2622"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(141)\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 1. Get the original image')\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_cnt)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 2. Find the biggest contour')\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_pnt)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 3. Find the extreme points')\n",
    "plt.subplot(144)\n",
    "plt.imshow(new_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 4. Crop the image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKHhKEQ5N4zq",
    "outputId": "801728b1-a03c-4f62-e2b3-d32df4c8648c"
   },
   "outputs": [],
   "source": [
    "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "x_train = [] # training images.\n",
    "y_train  = [] # training labels.\n",
    "x_test = [] # testing images.\n",
    "y_test = [] # testing labels.\n",
    "\n",
    "image_size = 200\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    trainPath = os.path.join('/content/drive/My Drive/brain_tumour/cropped/Training',label)\n",
    "    for file in tqdm(os.listdir(trainPath)):\n",
    "        image = cv2.imread(os.path.join(trainPath, file),0) # load images in gray.\n",
    "        image = cv2.bilateralFilter(image, 2, 50, 50) # remove images noise.\n",
    "        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE) # produce a pseudocolored image.\n",
    "        image = cv2.resize(image, (image_size, image_size)) # resize images into 150*150.\n",
    "        x_train.append(image)\n",
    "        y_train.append(labels.index(label))\n",
    "    \n",
    "    testPath = os.path.join('/content/drive/My Drive/brain_tumour/cropped/Testing',label)\n",
    "    for file in tqdm(os.listdir(testPath)):\n",
    "        image = cv2.imread(os.path.join(testPath, file),0)\n",
    "        image = cv2.bilateralFilter(image, 2, 50, 50)\n",
    "        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        x_test.append(image)\n",
    "        y_test.append(labels.index(label))\n",
    "\n",
    "\n",
    "x_train = np.array(x_train) / 255.0 # normalize Images into range 0 to 1.\n",
    "x_test = np.array(x_test) / 255.0\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "nfh2qiPAN8sm",
    "outputId": "bda484c8-22a9-472e-ae71-a77b107026b3"
   },
   "outputs": [],
   "source": [
    "images = [x_train[i] for i in range(15)]\n",
    "fig, axes = plt.subplots(3, 5, figsize = (10, 10))\n",
    "axes = axes.flatten()\n",
    "for img, ax in zip(images, axes):\n",
    "    ax.imshow(img)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCE5dMf1OMcf",
    "outputId": "7390bbd1-3401-42a4-9a31-e759e56c7796"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train,y_train, random_state=42) \n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train) #One Hot Encoding on the labels\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42) #Dividing the dataset into Training and Validation sets.\n",
    "\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-wD4DCjOTNN"
   },
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORzZLdlROs70"
   },
   "outputs": [],
   "source": [
    "# set the paramters we want to change randomly\n",
    "demo_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.05,\n",
    "    brightness_range=[0.1, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "os.mkdir('preview_2')\n",
    "x = x_train[0]  \n",
    "x = x.reshape((1,) + x.shape) \n",
    "\n",
    "i = 0\n",
    "for batch in demo_datagen.flow(x, batch_size=1, save_to_dir='preview_2', save_prefix='aug_img', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "N_CO0Z62O6UN",
    "outputId": "1150007a-9293-4589-ef0d-51b75f085c52"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x[0])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Original Image')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "i = 1\n",
    "for img in os.listdir('preview_2/'):\n",
    "    img = cv2.cv2.imread('preview_2/' + img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(3,7,i)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    i += 1\n",
    "    if i > 3*7:\n",
    "        break\n",
    "plt.suptitle('Augemented Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCsAaSEfPLvo"
   },
   "outputs": [],
   "source": [
    "# ImageDataGenerator transforms each image in the batch by a series of random translations, rotations, etc.\n",
    "datagen = ImageDataGenerator(\n",
    "     rotation_range=10,                        \n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# After you have created and configured your ImageDataGenerator, you must fit it on your data.\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKFq5pQpP3PG",
    "outputId": "6b1f70bd-b220-4c09-cf2e-60bbe0edb67b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "IMG_SIZE=(200,200)\n",
    "conv_base = ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzouAqQgQDUY",
    "outputId": "bc2ad832-6b75-47db-9486-aaca17541000"
   },
   "outputs": [],
   "source": [
    "model = conv_base.output\n",
    "model = GlobalAveragePooling2D()(model)\n",
    "model = Dropout(0.4)(model)\n",
    "model = Dense(4, activation=\"softmax\")(model)\n",
    "model = Model(inputs= conv_base.input, outputs= model)\n",
    "\n",
    "#compile our model.\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHEpv5MLQRMb"
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('.mdl_wts.hdf5', monitor='val_loss',mode='min',verbose=1, save_best_only=True),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min', min_lr=0.00000000001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzNpWNAvQT56",
    "outputId": "ef844ce2-d778-444a-9398-baaff2e228cb"
   },
   "outputs": [],
   "source": [
    "train_len = len(x_train)\n",
    "val_len = len(x_val)\n",
    "print(\"-----------Training Data length-----------------\")\n",
    "print(train_len)\n",
    "\n",
    "print(\"-----------Validation Data length-----------------\")\n",
    "print(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQlzLOj8Qbme",
    "outputId": "74ec1047-cc1b-4741-b0e9-671f478f7b92"
   },
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),validation_data = (x_val,y_val),epochs = 50,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukX5FaS6unQn"
   },
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "LKH4R3miuqy7",
    "outputId": "32e14cf4-9043-4a85-d3fe-b21a03fd3182"
   },
   "outputs": [],
   "source": [
    "#Plot the Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "#Plot the Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkxG3nvMuuh9"
   },
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9I-46H_2Qrq8"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at .mdl_wts.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9136\\1383069173.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mdl_wts.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/brain_tumour/modelres50.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/brain_tumour/modelres50.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                         raise IOError(\n\u001b[0m\u001b[0;32m    227\u001b[0m                             \u001b[1;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at .mdl_wts.hdf5"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('.mdl_wts.hdf5')\n",
    "model.save('/content/drive/My Drive/brain_tumour/modelres50.h5')\n",
    "\n",
    "model = load_model('/content/drive/My Drive/brain_tumour/modelres50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LynYGvy4vK-0"
   },
   "source": [
    "## Validation on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0dZj0tyGPUE",
    "outputId": "6b32afa1-c396-45ee-8bce-99c74f5f61f1"
   },
   "outputs": [],
   "source": [
    "loss,acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwb6Nw6ZvNH8",
    "outputId": "30b31ade-45a1-43dd-f76e-ccfbaa904ddd"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "predicted_classes = np.argmax(model.predict(x_test), axis = 1)\n",
    "print(classification_report(np.argmax(y_test,axis=1), predicted_classes,target_names=['glioma','meningioma','no_tumor','pituitary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "T_jl-5WqycLc",
    "outputId": "7042a131-129f-47a5-bdb0-c7168aaf7c6a"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "pred_Y = model.predict(x_test, batch_size = 8, verbose = True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    target_names=['glioma','meningioma','no_tumor','pituitary']\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test, batch_size=8)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(pred_Y,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "# compute the confusion matrix\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "confusion_mtx = confusion_matrix(rounded_labels, Y_pred_classes)\n",
    "\n",
    " \n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BQGGv6dw3H8M",
    "outputId": "8aa67684-f066-46b0-ae63-0bbd6def6acc"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "n_classes = 4\n",
    "\n",
    "pred_Y = model.predict(x_test, batch_size = 16, verbose = True)\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_Y[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), pred_Y.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSYLJ7Ub4Ri4"
   },
   "source": [
    "## Plotting sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "w3naeEPr33Kb",
    "outputId": "743fb2ef-91cd-40b5-9499-ce1b077af32c"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# define text labels \n",
    "target_labels = ['glioma','meningioma','no_tumor','pituitary']\n",
    "\n",
    "# plot a random sample of test images, their predicted labels, and ground truth\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=12, replace=False)):\n",
    "    ax = fig.add_subplot(4,4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(y_hat[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n",
    "                 color=(\"blue\" if pred_idx == true_idx else \"orange\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkmzwsUW6A_J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Brain Tumor classification.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
